{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T23:23:38.979367Z",
     "start_time": "2020-05-13T23:23:38.432591Z"
    }
   },
   "outputs": [],
   "source": [
    "# Web Scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# FAQ_ID labelling\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "starting_urls = ['https://support.n26.com/de-de',\n",
    "                 'https://support.n26.com/de-at',\n",
    "                 'https://support.n26.com/en-at',\n",
    "                 'https://support.n26.com/en-de',\n",
    "                 'https://support.n26.com/en-it',\n",
    "                 'https://support.n26.com/it-it',\n",
    "                 'https://support.n26.com/en-eu',\n",
    "                 'https://support.n26.com/en-fr',\n",
    "                 'https://support.n26.com/fr-fr',\n",
    "                 'https://support.n26.com/en-es',\n",
    "                 'https://support.n26.com/es-es',\n",
    "                 'https://support.n26.com/en-us',\n",
    "                 'https://support.n26.com/en-gb'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem statement\n",
    "\n",
    "The task is to find some data from a neobank named N26, and to match questions across languages. It's in affect a web scraping and clustering problem, which affected how this was approached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the FAQ data from the helpdesk of N26 across all markets (40%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl (40%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If stuck, use the below csv\n",
    "extracted_n26 = pd.read_csv('../data/extracted_n26.csv', index_col=0)\n",
    "extracted_data = extracted_n26.values.tolist()\n",
    "\n",
    "extracted_n26_no_duplicates = extracted_n26.drop_duplicates(subset=['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>market</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://support.n26.com/de-at/app-und-produkte...</td>\n",
       "      <td>de-at</td>\n",
       "      <td>Was sind Spaces?</td>\n",
       "      <td>Setze dir Ziele, erstelle, personalisiere und ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://support.n26.com/en-es/account-and-pers...</td>\n",
       "      <td>en-es</td>\n",
       "      <td>How to download my personal data?</td>\n",
       "      <td>The General Data Protection Regulation (GDPR) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://support.n26.com/de-at/zahlungen-ueberw...</td>\n",
       "      <td>de-at</td>\n",
       "      <td>Wie lange dauert eine Überweisung mit Transfer...</td>\n",
       "      <td>Wenn du eine Überweisung mit TransferWise mach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://support.n26.com/en-de/app-and-features...</td>\n",
       "      <td>en-de</td>\n",
       "      <td>How to manage my visibility as an N26 user?</td>\n",
       "      <td>To grant you access to all our in-app features...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://support.n26.com/en-de/payments-transfe...</td>\n",
       "      <td>en-de</td>\n",
       "      <td>How often can I withdraw cash for free?</td>\n",
       "      <td>Cash withdrawals using your Mastercard depend ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url market  \\\n",
       "0  https://support.n26.com/de-at/app-und-produkte...  de-at   \n",
       "1  https://support.n26.com/en-es/account-and-pers...  en-es   \n",
       "2  https://support.n26.com/de-at/zahlungen-ueberw...  de-at   \n",
       "3  https://support.n26.com/en-de/app-and-features...  en-de   \n",
       "4  https://support.n26.com/en-de/payments-transfe...  en-de   \n",
       "\n",
       "                                               title  \\\n",
       "0                                   Was sind Spaces?   \n",
       "1                  How to download my personal data?   \n",
       "2  Wie lange dauert eine Überweisung mit Transfer...   \n",
       "3        How to manage my visibility as an N26 user?   \n",
       "4            How often can I withdraw cash for free?   \n",
       "\n",
       "                                             content  \n",
       "0  Setze dir Ziele, erstelle, personalisiere und ...  \n",
       "1  The General Data Protection Regulation (GDPR) ...  \n",
       "2  Wenn du eine Überweisung mit TransferWise mach...  \n",
       "3  To grant you access to all our in-app features...  \n",
       "4  Cash withdrawals using your Mastercard depend ...  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_n26.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df length: 1412\n",
      "df length without duplicates: 654\n"
     ]
    }
   ],
   "source": [
    "print('df length:', len(extracted_n26))\n",
    "print('df length without duplicates:',len(extracted_n26_no_duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [52:03<00:00, 240.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set up dataframe for use in crawling\n",
    "df = pd.DataFrame(columns=['url', 'market', 'title', 'content'])\n",
    "\n",
    "\n",
    "# crawl, extract and record relevant information\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}\n",
    "i = 0\n",
    "errors = []\n",
    "\n",
    "for url in tqdm(starting_urls):\n",
    "    \n",
    "    # get faq links from page (it's only the first 6 that we need)\n",
    "    page = requests.get(url, headers=headers)\n",
    "    faq_soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    market = url[-5:]\n",
    "    faq_links = [link['href'] for link in faq_soup.find_all('a') if link['href'].startswith('/'+ market +'/')][:6]\n",
    "    \n",
    "    # get titles and title links links from faq links\n",
    "    for link in faq_links:\n",
    "        q_page = requests.get(url+link[6:], headers) \n",
    "        q_soup = BeautifulSoup(q_page.content, 'html.parser')\n",
    "        q_links = [link['href'] for link in q_soup.find_all('a') \n",
    "                   if link['href'].startswith('/'+ market +'/')\n",
    "                   and link.string.endswith('?')]\n",
    "        titles = [link.string for link in q_soup.find_all('a')\n",
    "                       if link.string is not None and link.string.endswith('?')]\n",
    "        \n",
    "        # get answers from question links and put everything into the dataframe set up earlier\n",
    "        for q, q_link in enumerate(q_links):\n",
    "            try:\n",
    "                a_page = requests.get(url + q_link[6:], headers)\n",
    "                a_source = BeautifulSoup(a_page.content, 'html.parser')\n",
    "                a = a_source.find(id = 'main').get_text().split('?')[1:][0]\n",
    "                df.at[i,'url'] = url + q_link[6:]\n",
    "                df.at[i,'market'] = market\n",
    "                df.at[i,'title'] = titles[q]\n",
    "                df.at[i,'content'] = a\n",
    "                i= i +1\n",
    "            except AttributeError as error:\n",
    "                errors.append([f'{error} for url: {url + q_link[6:]}'])\n",
    "                continue\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_duplicates = df.drop_duplicates(subset=['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>market</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://support.n26.com/de-de/konto-und-person...</td>\n",
       "      <td>de-de</td>\n",
       "      <td>Kann ich in meinem Land ein N26 Konto eröffnen?</td>\n",
       "      <td>Wir bieten unsere Konten in folgenden Ländern ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://support.n26.com/de-de/konto-und-person...</td>\n",
       "      <td>de-de</td>\n",
       "      <td>Kann ich ein Konto eröffnen, wenn ich außerhal...</td>\n",
       "      <td>Wenn du in Polen, Schweden, Dänemark, Norwegen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://support.n26.com/de-de/konto-und-person...</td>\n",
       "      <td>de-de</td>\n",
       "      <td>Wie eröffne ich mein N26 Konto?</td>\n",
       "      <td>Du kannst ein N26 Konto in der App (auf deinem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://support.n26.com/de-de/konto-und-person...</td>\n",
       "      <td>de-de</td>\n",
       "      <td>Warum funktioniert meine Video-Verifizierung n...</td>\n",
       "      <td>Einige Tipps für eine erfolgreiche Video-Verif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://support.n26.com/de-de/konto-und-person...</td>\n",
       "      <td>de-de</td>\n",
       "      <td>Wie kann ich mich ausweisen?</td>\n",
       "      <td>Als Bank müssen wir wissen, wer du bist. Desha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url market  \\\n",
       "0  https://support.n26.com/de-de/konto-und-person...  de-de   \n",
       "1  https://support.n26.com/de-de/konto-und-person...  de-de   \n",
       "2  https://support.n26.com/de-de/konto-und-person...  de-de   \n",
       "3  https://support.n26.com/de-de/konto-und-person...  de-de   \n",
       "4  https://support.n26.com/de-de/konto-und-person...  de-de   \n",
       "\n",
       "                                               title  \\\n",
       "0    Kann ich in meinem Land ein N26 Konto eröffnen?   \n",
       "1  Kann ich ein Konto eröffnen, wenn ich außerhal...   \n",
       "2                    Wie eröffne ich mein N26 Konto?   \n",
       "3  Warum funktioniert meine Video-Verifizierung n...   \n",
       "4                       Wie kann ich mich ausweisen?   \n",
       "\n",
       "                                             content  \n",
       "0  Wir bieten unsere Konten in folgenden Ländern ...  \n",
       "1  Wenn du in Polen, Schweden, Dänemark, Norwegen...  \n",
       "2  Du kannst ein N26 Konto in der App (auf deinem...  \n",
       "3  Einige Tipps für eine erfolgreiche Video-Verif...  \n",
       "4  Als Bank müssen wir wissen, wer du bist. Desha...  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df length: 1124\n",
      "df length without duplicates: 580\n"
     ]
    }
   ],
   "source": [
    "print('df length:', len(df))\n",
    "print('df length without duplicates:',len(df_no_duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 5\n",
      "Error example: [\"'NoneType' object has no attribute 'get_text' for url: https://support.n26.com/en-eu/security/passwords-and-codes/why-didnt-i-receive-my-pairing-code-via-sms\"]\n"
     ]
    }
   ],
   "source": [
    "print('Number of errors:',len(errors))\n",
    "print('Error example:',errors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding closest matches (60%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding questions that match from a group of questions is effectively a clustering problem. As it is a clustering problem, we'll need some way of turning the text into something that can be 'clustered'; in machine learning, clustering means finding the distances in vector space between vectors, and giving the same label to vectors within a given distance. \n",
    "\n",
    "The workflow will look like this:\n",
    "\n",
    "\n",
    "\n",
    "1. <b> Get universal encoder from tensorflow </b> - The FAQs are in different languages. The Universal Sentence Encoder will help us to understand the context around words, even in different languages. \n",
    "2.<b> _Embed the question answers_ </b>- In order to cluster our answers, we'll use the encoder to represent our answers in vector form. There will be 512 numbers in each vector, corresponding to 512 distances that describe our answers.\n",
    "3. <b>_Scale the embeddings_ </b>- Using sentences for text embedding often results in the embeddings becoming diluted: it's harder to tell the meaning of sentences apart from each other than it is for words, and this will reflect in the embedding. Scaling the embeddings will preserve the relationship between the embeddings mathematically, whilst making the differences more stark.\n",
    "4. <b>_Cluster the embeddings_ </b>- scikit-learn has many clustering algorithms. OPTICS and DBScan are optimised for high dimensional data, and OPTICS more so according to the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html).\n",
    "5. <b>_Attach the cluster labels to the FAQs_</b> - We'll put all this work into a dataframe to be exported.\n",
    "\n",
    "We'll also look at how good the culstering is when there are no repeated questions, as this should force cross language matching better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the encoder from Tensorflow Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. In order to match the question answers to each other, the universal sentence encoder provided by tensorflow was used to create vector representations of each sentence on the data set (i.e. to create sentence embeddings). We can get the universal sentence encoder from the tensorflow hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T23:28:29.499675Z",
     "start_time": "2020-05-13T23:24:28.333692Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function recreate_function.<locals>.restored_function_body at 0x000002866AB75DC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function recreate_function.<locals>.restored_function_body at 0x000002866AB75DC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000286E8B598B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000286E8B598B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n",
      "Wall time: 28.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# for the purposes of the interview we stongly encourage you to use the universal sentence encoder\n",
    "# The following code will setup everything you need and setup the encoder for you\n",
    "\n",
    "# For full disclaimer this code has been taken from\n",
    "# Semantic Similarity with TF-Hub Universal Encoder at tf hub\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)\n",
    "print (f\"module {module_url} loaded\")\n",
    "def embed(input):\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answers from the scraped data dataframe will provide the basis for the embedding. Lets embed our answers and have a look at what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of message: 3D Secure est une technologie de sécurisation des paiements en ligne visant à limiter l’utilisation frauduleuse des cartes bancaires sur internet \n",
      "\n",
      "Embedding size: 512\n",
      "First 3 embeddings: [-0.06545603 -0.06586096  0.008463  ]\n",
      "Standard deviation: 0.044067346\n",
      "\n",
      "\n",
      "\n",
      "Start of message: If you hold an US account with N26 Inc \n",
      "\n",
      "Embedding size: 512\n",
      "First 3 embeddings: [-0.05529587 -0.03282806  0.05686469]\n",
      "Standard deviation: 0.044184644\n",
      "\n",
      "\n",
      "\n",
      "Start of message: If you suspect possible fraudulent activity on your account, please contact us as soon as possible \n",
      "\n",
      "Embedding size: 512\n",
      "First 3 embeddings: [-0.06628229  0.00125737  0.0411117 ]\n",
      "Standard deviation: 0.044156652\n",
      "\n",
      "\n",
      "\n",
      "Wall time: 45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "messages = df.sample(n=3).content\n",
    "message_tensors = embed(messages)\n",
    "\n",
    "for i, tensor in enumerate(message_tensors[:3]):\n",
    "    print(f'Start of message: {messages.to_list()[i].split(\".\")[0]} \\n')\n",
    "    print(f'Embedding size: {len(tensor)}')\n",
    "    print(f'First 3 embeddings: {tensor[:3]}')\n",
    "    print('Standard deviation:', np.std(tensor))\n",
    "    print('\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the distances from answer to answer are really, really small. The standard deviation is comparable to the embedding values, implying the answers within the vector space aren't very well defined. This will drastically affect the quality of the clusters extracted, but we should still be able to get some reasonable results (maybe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will implement steps 2 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T23:29:49.081589Z",
     "start_time": "2020-05-13T23:29:49.076773Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bless\\Anaconda3\\envs\\MLEnv\\lib\\site-packages\\sklearn\\cluster\\_optics.py:802: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n",
      "C:\\Users\\bless\\Anaconda3\\envs\\MLEnv\\lib\\site-packages\\sklearn\\cluster\\_optics.py:802: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def match_qas(qas_across_markets_df):\n",
    "    \"\"\"    \n",
    "    This function assigns an faq_id to the input data, thus grouping question\n",
    "    answer pairs across languages. A locale is the language of a market\n",
    "    \n",
    "    Parameters:\n",
    "       qas_across_markets (list[\n",
    "                         (market_1,url_1,title_1,content_1),\n",
    "                         (market_2,url_2,title_2,content_2)])\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "       matched_data (list[\n",
    "                         (faq_id_1,locale_1,market_1,title_1,content_1),\n",
    "                         (faq_id_1,locale_2,market_2,title_2,content_2)])\n",
    "    \"\"\"\n",
    "    \n",
    "    # The data has structure (questions with the same language will be grouped together, due to the structure of the site).\n",
    "    # This structure may interfere with our clusters, so we shuffle the data to fix that.\n",
    "    shuffled_df = qas_across_markets_df.sample(frac=1, random_state=42)\n",
    "    \n",
    "    # Step 2\n",
    "    embeddings = embed(shuffled_df.content)\n",
    "    \n",
    "    # Step 3\n",
    "    # MaxAbsScaler is used for no particular reason other than it's slightly simpler than the alternatives,\n",
    "    # and plays nicer with OPTICS.\n",
    "    scalar = MaxAbsScaler()\n",
    "    scaled_embeddings = scalar.fit_transform(embeddings)\n",
    "    \n",
    "    # Step 4\n",
    "    # OPTICS is used to cluster the data for reasons mentioned earlier.\n",
    "    clusters = OPTICS(n_jobs=-1, min_cluster_size=4, metric='cosine' ).fit(scaled_embeddings)\n",
    "    \n",
    "    # Step 4\n",
    "    # The labels from the clusters are put into a dataframe along with the rest of the relevant data.\n",
    "    locale_market = shuffled_df.market.str.split(pat='-', expand  = True)\n",
    "\n",
    "    data_dict = {'FAQ_id':clusters.labels_+1 , 'locale':locale_market[0], 'market': locale_market[1],\n",
    "             'title':shuffled_df.title.to_list(), 'content':shuffled_df.content.to_list()}\n",
    "    \n",
    "    matched_data = pd.DataFrame.from_dict(data_dict)\n",
    "    return matched_data\n",
    "    \n",
    "\n",
    "test_results = match_qas(extracted_n26)\n",
    "final_results = match_qas(df)\n",
    "\n",
    "# Add a version with the duplicates dropped. This should reduce the amount of clusters \n",
    "# and better match questions across languages as some redundancy is removed \n",
    "\n",
    "test_results_2 = match_qas(extracted_n26_no_duplicates)\n",
    "final_results_2 = match_qas(df_no_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of faq ids for given data: 117\n",
      "No of faq ids for given data without duplicates: 13\n",
      "\n",
      "\n",
      "The amount of FAQ IDs found for scraped data: 101\n",
      "The amount of FAQ IDs found for scraped data without duplicates: 7\n"
     ]
    }
   ],
   "source": [
    "print('No of faq ids for given data:',len(test_results.FAQ_id.unique()))\n",
    "print('No of faq ids for given data without duplicates:',len(test_results_2.FAQ_id.unique()))\n",
    "print('\\n')\n",
    "print('The amount of FAQ IDs found for scraped data:',len(final_results.FAQ_id.unique()))\n",
    "print('The amount of FAQ IDs found for scraped data without duplicates:',len(final_results_2.FAQ_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAQ_id</th>\n",
       "      <th>locale</th>\n",
       "      <th>market</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>at</td>\n",
       "      <td>How to order my card with express delivery?</td>\n",
       "      <td>Express delivery is a good option if you need ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>3</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr</td>\n",
       "      <td>Quand est-ce que je recevrai ma carte ?</td>\n",
       "      <td>Voici les délais de livraison normaux une fois...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>at</td>\n",
       "      <td>When will my card arrive?</td>\n",
       "      <td>The estimated delivery timeline for card deliv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>3</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr</td>\n",
       "      <td>Comment commander ma carte en livraison express ?</td>\n",
       "      <td>Disponibilité limitée.La livraison express est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>3</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr</td>\n",
       "      <td>Comment commander une nouvelle carte ?</td>\n",
       "      <td>ℹ️ La livraison de votre carte peut prendre ju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FAQ_id locale market                                              title  \\\n",
       "223       3     en     at        How to order my card with express delivery?   \n",
       "817       3     fr     fr            Quand est-ce que je recevrai ma carte ?   \n",
       "222       3     en     at                          When will my card arrive?   \n",
       "818       3     fr     fr  Comment commander ma carte en livraison express ?   \n",
       "819       3     fr     fr             Comment commander une nouvelle carte ?   \n",
       "\n",
       "                                               content  \n",
       "223  Express delivery is a good option if you need ...  \n",
       "817  Voici les délais de livraison normaux une fois...  \n",
       "222  The estimated delivery timeline for card deliv...  \n",
       "818  Disponibilité limitée.La livraison express est...  \n",
       "819  ℹ️ La livraison de votre carte peut prendre ju...  "
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clusters 1 to 4 showed some question matching\n",
    "final_results_2.loc[final_results_2.FAQ_id == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we attempted to match questions across languages by clustering them with a scikit-learn implementation of OPTICS, a density-based clustering algorithm tuned to high-dimensional data such as ours. We met VERY limited success, due to the curse of dimensionality and the narrowness of the topic at hand.\n",
    "\n",
    "There should have been a cluster for every question from the 6 FAQ links scraped, but instead only 7 were found \n",
    "\n",
    "Some matching between French and English was made, probably because they're the two closest languages to each other. The clustering seemed mainly to focus on the language/words used and not the context of the words, resulting in the massive bucket of left-over content in the last bucket.\n",
    "\n",
    "Some tuning of OPTICS clustering would improve this a lot, but after a few different parameters were tried and tested the results didn't get any better or more defined than they are now. Perhaps another approach could produced a more informative clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll save the scraped data that was used for machine learning, and the two results of machine learning, for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data_fname = 'extracted_data_n26.csv'\n",
    "final_results_fname = 'n26_with_faq_.csv'\n",
    "test_results_fname = 'result_with_given_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(extracted_data_fname)\n",
    "final_results_2.to_csv(final_results_fname)\n",
    "test_results_2.to_csv(test_results_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T23:29:51.475970Z",
     "start_time": "2020-05-13T23:29:51.471383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dump file in a csv called n26_with_faq_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
